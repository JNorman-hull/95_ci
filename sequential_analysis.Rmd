---
title: "Fixed-Width Sequential Confidence Interval Testing"
author: "Josh Norman"
date: "2025-07-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.width = 8,
  fig.height = 6,
  fig.align = "center"
)
knitr::opts_knit$set(root.dir = getwd())
```

# 1. Introduction

This analysis aims to produce a viable Fixed-Width Sequential Confidence Interval Testing method for designing live fish trials with defined points to accept or reject null hypothesis and continue testing.

Fixed-precision Sequential Confidence Interval Testing

Fixed-width sequential confidence interval testing is a statistical method used to estimate a parameter (e.g., mean, proportion) with a predetermined precision while dynamically adjusting the sample size based on accumulating data. Unlike fixed-sample designs, this approach continuously monitors the width of the confidence interval (CI) during data collection, stopping only once the CI narrows to a pre-specified fixed width, ensuring the estimate meets the desired margin of error. Sequential testing is particularly useful when data collection is costly or time-consuming, as it often requires fewer observations than fixed-sample methods while maintaining statistical validity.

We deviate from this principle by fixing our precision level as apposed to the width of the CI.

Ensure we calculate our confidence intervals based on the survival probability, NOT, the mortality probability. This may be a source of error for the previous differences in calculations. 

At each sampling point (e.g., every n = 100), calculate Wilson confidence intervals for observed mortality number. This will inherently deviate from fixed-width CI as the CI width is determined by observed mortality and sample size.

Decision rules to estimate probability with a given precision level (differs from hypothesis based testing):

-   Desired threshold for survival ≥ 98%

-   Not fish-friendly : If upper 95% CI \< 98%

-   Fish-friendly: If observed survival ≥ 98% and lower 95% CI ≥ 94%

-   Continue testing: Otherwise

The continue zone therefore directly controls the estimation error and we do not apply traditional hypothesis based testing.\
\
**Accepting only when results are clear and conservative (\>98% + LB ≥ 94%). Rejecting only when results are definitively bad (UB \< 98%). Continuing otherwise—no gray-area decisions.**

**Type I/II Error Control**

-   **Type I Error (False "Accept"):**

    -   Controlled by requiring **LB ≥ 94% AND observed \> 98%**.

    -   This is stricter than classic hypothesis tests (reduces false positives).

-   **Type II Error (False "Reject"):**

    -   Controlled by **only rejecting if UB \< 98%** (avoids premature rejection)

**Conservatism**

-   Sequential testing is required in our application as we do not have sufficient knowledge of the actual mortality rate to apply a fixed sample size. 

-   Our first sample occurs at 100, which has already significantly reduced our likelihood of committing a type I error. We simply maintain our artificial alpha spend linearly throughout the experiment. Bare in mind there is no true alpha when we are just examining within group probability and want a fixed precision. That will come in the next approach of comparing impact to control groups.

-   The criteria for rejecting the null are already high by requiring an upper bounds to not include 98.

-   Fixed lower bound rule is a conservative measure to guarantee fixed estimation lower bounds.

Because this restriction is already conservative, we choose not to apply any further adjustment to the confidence intervals.

# 2. Required libraries

```{r libraries, echo=FALSE}
#library(here)
library(tidyverse)
library(binom)
library(scales)
library(plotly)
library(survey) 
library(htmltools)
#library(gganimate)
#library(ggpubr)
#library(gt)
#library(kableExtra)

#Source functions for calculations, plots etc
source("./functions.R")

```

# 3. Generate mortality data

Construct the mortality table using a max sample size, desired survival and acceptable lower bound estimate. 

95% CI = Wilson binomial. R packaage 'binom'
Key calculation:

```{r eval=FALSE}
conf <- binom.confint(n_mortality, n, methods = "wilson")
```

```{r mortality_table, eval = FALSE, echo = FALSE}

mortality_data <- create_mortality_table(
  max_sample_size = 1000,
  step_size = 1,
  lower_threshold = 96,
  desired_surv = 98,
  max_mortality_proportion = 0.5
)

#using step size of 1 creates mortality table robust to any recapture rate

write.csv(mortality_data, "./output/mortality_data.csv", row.names = FALSE)

mortality_sample_plot <- create_decision_plot(mortality_data)
mortality_sample_plot

ggsave(filename = "./output/mortality.svg", plot = mortality_sample_plot,
     units="cm",width=14,height=14)

```

# 3.1 Simulate trial outcomes

Where recapture rate < 100% we need a method to estimate mortality across our observed (recaptured) and unobserved (missing) fish.

Horvitz–Thompson estimator

Key assumption of H-T estimator:

The HT estimator is designed for unbiased estimation under unequal probability sampling, which aligns well with:

 - Known recapture rate (i.e., sampling probability for each fish)

 - A known total number of exposed individuals (the finite population correction, FPC)
 
 - The assumption that mortality is independent of recapture (i.e., missingness is random or at least conditionally ignorable). If unrecaptured fish may have higher or lower mortality, then the HT estimator is biased because the missingness is not at random. This is a core limitation: HT assumes known inclusion probabilities and that these are not related to the variable of interest (here, mortality).

In reality, we may violate this assumption, but we have no prior information to reasonably assume this. Therefore, we can only assume that mortality is at random.

However... H-T provides a defensible first-pass estimate, especially if paired with finite population control (we always have this!)

How may we handle the violation?

Effective sensitivity analysis.

The H-T confidence interval says how uncertain we are in the mortality estimate when we have only observed part of the population, assuming recaptured fish are a random sample. The lower bound of the CI reflects the minimum plausible mortality, the upper bound reflects the maximum plausible mortality.

We accept that the CI bounds assume random sampling, but we apply the lower and upper bounds to allow for uncertainty due to incomplete observation. We do not believe there is a strong bias (assuming random), but want a defensible lower-end estimate.

The CI is derived from normal approximation.

For example:

300 fish exposed
270 recaptured
27 deaths observed, observed mortality = 27/270 = 10%
HT point estimate = 27/270 x 300 = 30 deaths
HT 95% CI: (26.6, 33.4) = 26.6/300 (8.87% mortality), = 33.4/300 (11.13% mortality)

So, under the assumption that the recaptured fish are representative (e.g., assuming random mortality), the true population mortality rate is likely between 8.9% and 11.1% with 95% confidence.

We do not know mortality is random, so we can infer the lower and upper mortality estimates as potentially representing scenarios where mortality is biased in those groups (e.g., lower/higher mortality in missing fish). In this scenario, the lower bounds are always going to represent mortality of 0 in the missing fish.

What do the bounds potentially imply about missing fish?

Implied death in missing fish:

Lower = 26.6 - 27 = -0.4 (not possible death, so assume 0) e.g., 10% percentage points less mortality than recaptured)
Upper = 33.4 - 27 = 6.4 = 6.4/30 = 21.3% (e.g., 11.13% percentage points more morality than recaptured)

These lower and upper bounds are therefore inferential of what COULD'VE happened to the fish. More or less fish may have died in the missing group.

Under the assumptions of the HT estimator, and based on the confidence interval of total mortality, mortality among unrecaptured fish could plausibly range from near 0% (if all survived) to 21.3% (if 6.4 of 30 died). This reflects the uncertainty due to both sampling variation and the unknown fate of missing fish, but does not account for systematic bias if missingness is not random.

Key calculation: R packaage 'survey'

```{r eval= FALSE}
 # Create data frame for survey design
  recaptured_data <- data.frame(
    death = c(rep(1, observed_deaths), rep(0, observed_survivors)),
    weight = 1 / recapture_rate,
    fpc = exposed_fish
  )
  
  # Survey design with finite population correction
  design <- svydesign(
    ids = ~1,           
    weights = ~weight,  
    fpc = ~fpc,        
    data = recaptured_data
  )
  
  # Calculate HT estimate
  ht_total <- svytotal(~death, design)
  ht_ci <- confint(ht_total)

```

Simulate sequential trial decisions using Horvitz–Thompson estimator.

Three levels of estimation
    aggressive = accept earlier (lowest death estimate mortality lower in missing fish)
    neutral = marginal inflation of lower bounds (mortality assumed equal in missing fish)
    conservative = reject earlier (highest death estimate mortality higher in missing fish)

```{r horvitz–hompson_estimator, eval = FALSE}

execution_time <- system.time(
  ht_simulation_results <- run_ht_all_scenarios(
    simulations = 1:1000,
    max_sample = 1000,
    true_survival_rates = round(seq(0.90, 1, 0.01), 2),
    check_intervals = c(100, 200, 300, 400, 500, 600, 700, 800, 900, 1000),
    mortality_table = mortality_data,
    recapture_rates = round(seq(0.90, 1, 0.01), 2)
  )
)

print(execution_time)

# Takes ~ 2 hours

write.csv(ht_simulation_results, "./output/ht_simulation_results.csv")

```

# 4. Import

Import pre-calculated mortality data and simulation results.

Mortality data:
Desired survival 98%
Lowwer bounds acceptance 96%

Simulation data:
  Max sample size = 1000
  Simulations (for each interval) = 1000
  true_survival_rates = 90 - 100%
  check_intervals = 100 - 1000, by 100
  recapture_rates = 90 - 100%

```{r input_import, echo = FALSE}

mortality_data  <- read.csv("./input/mortality_data_98surv_96lower_step1.csv")
ht_simulation_results  <- read.csv("./input/ht_simulation_results.csv")

#Create demo dataset
#demo_mortality <- mortality_data[sample(nrow(mortality_data), 100), ]
#demo_simulation <- ht_simulation_results[sample(nrow(ht_simulation_results), 100), ]
#write.csv(demo_mortality, "./output/demo_mortality.csv")
#write.csv(demo_simulation, "./output/demo_simulation.csv")

```


# 5. Useage

Create interactive plot for decision making.

```{r plotly, echo=FALSE, eval = FALSE}

decision_point <- mortality_sample_plot +
  geom_point(data = mortality_data, 
             aes(x = sample_size, y = n_mortality, 
                 text = paste("Sample size:", sample_size, "<br>", 
                             survival_formatted),  color = decision),
             alpha = 0, size = 1)+
  scale_color_manual(
    values = c(
      "Accept H0" = "darkgreen", 
      "Reject H0" = "darkred", 
      "Continue" = "grey50"
    )
  )

decision_point$layers <- decision_point$layers[
  !sapply(decision_point$layers, function(x) inherits(x$geom, "GeomText"))
]

decision_point_plotly <- ggplotly(decision_point, tooltip = "text") %>%
tmp <- tempfile(fileext = ".html")
htmlwidgets::saveWidget(decision_point_plotly, tmp)
browseURL(tmp)

```



```{r}

# Plot a specific simulation scenario when working live
# e.g.,  assumed true survival is 95% at interval 300, what do sequential test routes to rejecting null hypothesis this look like? 
# At 300 fish 
# We have a cumulative re-catch of 278 (22 missing fish)
# We have observed 7 dead fish 

# Survival probability of recaptured fish
#271/278 = 97.48%
# Recapture rate
#278/300 = 92.7%
# These show which lookup conditions to input for the simulation

#We then measure mortality with 3 methods and perform sensitivity analysis
#Run with defaults first, then can input the assumed_true_survival (0.98) and recapture_rate_scenario (1) afterwards

my_decisions <- analyze_real_study_data_enhanced(
  exposed_fish = 300,
  recaptured_fish = 270, 
  observed_deaths = 27,
  mortality_table = mortality_data,
  cumulative_data = cumulative_all,
  assumed_true_survival = 0.90,
  recapture_rate_scenario = 0.90 
)

#needs to 
# show stopping proportions plot
# show simulated trials plot
# show sensitivity analysis plot

```

# 5.1 Lookup results

```{r}
# lookup specific rows (sample, mortality)
lookup_mortality_data(mortality_data, 400, 7) 
lookup_mortality_data(mortality_data, 360, 7) 

# need to add lookup for simulation results too, so we can quickly identify decision points
```

# 5.2 Visualise trial outcomes

Using the simulation output, we can now determine what scenarios are most likely to occur during sequential testing. This allows us to determine our stopping rate at given sample itnervals and given mortality estimates.

```{r}

# Plot simulations for 90 - 100% survival, 90% and 100% recapture using the neutral method. Mortality in missing fish assumed to be random (like observed fish)

journey_plot_recapture <- create_journey_plot_ht_comprehensive(
  mortality_data,
  ht_simulation_results_fixed,
  survival_rates_to_show = c(0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99,  1),
    recapture_rates_to_show = c(0.9, 1.0),
  decision_methods_to_show = c("neutral"),
  n_journeys = 1000
)

journey_plot_recapture$layers <- journey_plot_recapture$layers[
  !sapply(journey_plot_recapture$layers, function(x) inherits(x$geom, "GeomText"))
]

journey_plot_recapture

```


```{r}

# Plot simulations for specific survival and recapture rate, three mortality estimates

journey_plot_recap_method <- create_journey_plot_ht_comprehensive(
  mortality_data,
  ht_simulation_results_fixed,
  survival_rates_to_show = c( 0.98),
    recapture_rates_to_show = c(0.93),
  decision_methods_to_show = c("neutral", "aggressive", "conservative"),
  n_journeys = 1000
)

journey_plot_recap_method$layers <- journey_plot_recap_method$layers[
  !sapply(journey_plot_recap_method$layers, function(x) inherits(x$geom, "GeomText"))
]

journey_plot_recap_method

```


Need to add ability to plot specific simulations e.g.,

We're at interval 300
- what do scenarios which end here look like?
- what do scenarios which end at the next interval look like?

# 5.2 Stopping decisions

Now, we need to understand when we are most likely to stop, at a given sample interval, for a given true survival rate and recapture 


```{r}

ht_neutral <- ht_simulation_results %>% 
  filter(decision_method == "neutral")

ht_aggressive<- ht_simulation_results %>% 
  filter(decision_method == "aggressive")

ht_conservative <- ht_simulation_results %>% 
  filter(decision_method == "conservative")

cumulative_data_neutral <- calculate_cumulative_stopping(ht_neutral)
cumulative_data_conservative<- calculate_cumulative_stopping(ht_conservative)
cumulative_data_aggressive<- calculate_cumulative_stopping(ht_aggressive)

# Combine and add method labels to create complete lookup table for stopping decisions
cumulative_all <- bind_rows(
  cumulative_data_aggressive %>% mutate(decision_method = "aggressive"),
  cumulative_data_neutral %>% mutate(decision_method = "neutral"),
  cumulative_data_conservative %>% mutate(decision_method = "conservative")
)

#write.csv(cumulative_all, "./output/cumulative_all.csv")

```

```{r}

#use lookup table to find specific example of stopping point for a given scenario 
# How many have stopped and accepted, rejected or continued by now using a given method?
# Lookup from cumulative table

stopping_93_recap_all_methods <- cumulative_all %>%
  filter(
    true_survival_rate == 0.98,
    recapture_rate == 0.93
  ) %>%
  select(
    decision_method,
    interval,
    prop_accept_by_now,
    prop_reject_by_now,
    prop_continue,
    prop_stopped_by_now
  ) %>%
  arrange(decision_method, interval)

#Alternativley, we can look just at how many trials have stopped usign a specific method
# Given surivival, recapture rate, how many trials have stopped by a given sample interval?
stopping_93_recap_method <- cumulative_all %>%
  filter(
    true_survival_rate == 0.98,
    recapture_rate == 0.93
  ) %>%
  select(interval, decision_method, prop_stopped_by_now)

# Pivot to wide format for easy comparison
stopping_93_recap_method <- stopping_93_recap_method %>%
  pivot_wider(names_from = decision_method, values_from = prop_stopped_by_now)

```


# 5.2.1 Inconclusivity rates

Assuming a max interval size of 1000

```{r}

inconclusivity_by_method <- cumulative_all %>%
  filter(interval == 1000) %>%
  select(true_survival_rate, recapture_rate, decision_method, prop_continue) %>%
  pivot_wider(names_from = recapture_rate, 
              values_from = prop_continue,
              names_prefix = "recapture_") %>%
  mutate(across(starts_with("recapture_"), ~ round(.x * 100, 1))) %>%
  arrange(decision_method, true_survival_rate)

inconclusivity_by_method

```

# 5.3 Visualise stopping decisions

We can now visualise our stopping decisions to provide a visual reference for when continuing sampling is a worthy trade-off

```{r}

# Plot all survival and recapture conditions as a facet matrix 

plot_cumulative_stopping(cumulative_all, 
                         decision_method_filter = "neutral")

#decision_method_filter = "conservative"
#decision_method_filter = "aggressive"

```

```{r}

#Plot specific scenario showing difference across recapture method
stopping_plot <- plot_cumulative_stopping(cumulative_all,
                                          survival_filter = 0.98, 
                                          recapture_filter = 0.93)
stopping_plot

#Plot needs to be arranged correctly

```

Make sure all our plot methods arrange the recapture method as aggressive, netural, conservative

# 5.4 Visualise Type I error

We can examine the influence of our recapture estimate on type I error.

```{r}


#Examine acceptance rate across all

cumulative_plot <- ggplot(cumulative_all, 
                         aes(x = interval, y = prop_accept_by_now, 
                             color = decision_method, linetype = decision_method)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = c("aggressive" = "blue", "neutral" = "black", "conservative" = "red")) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_continuous(breaks = c(100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)) +
  labs(
    title = "Cumulative Acceptance Rate by Sample Interval and Decision Method",
    x = "Sample Interval",
    y = "Cumulative Proportion Accepting H0",
    color = "Decision Method",
    linetype = "Decision Method"
  ) +
  theme_JN() +
  facet_grid(recapture_rate ~ true_survival_rate, 
             labeller = labeller(recapture_rate = function(x) paste("Recapture:", x),
                               true_survival_rate = function(x) paste("Survival:", x)))

cumulative_plot


```

```{r}

#Examine acceptance rate across all methods for specific survival and recapture

cumulative_plot_9398 <- cumulative_all %>% 
  filter(true_survival_rate == 0.98, recapture_rate == 0.93) %>%
  select(decision_method, interval, prop_accept_by_now, prop_reject_by_now, prop_continue) %>%
  pivot_longer(cols = c(prop_accept_by_now, prop_reject_by_now, prop_continue),
               names_to = "outcome", 
               values_to = "proportion") %>%
  mutate(
    outcome = case_when(
      outcome == "prop_accept_by_now" ~ "Accept H0",
      outcome == "prop_reject_by_now" ~ "Reject H0", 
      outcome == "prop_continue" ~ "Continue"
    )
  ) %>%
  ggplot(aes(x = interval, y = proportion, 
             color = decision_method, linetype = decision_method)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = c("aggressive" = "blue", "neutral" = "black", "conservative" = "red")) +
  scale_y_continuous(labels = scales::percent_format()) +
  scale_x_continuous(breaks = c(100, 200, 300, 400, 500, 600, 700, 800, 900, 1000)) +
  labs(
    title = "Cumulative Trial Outcomes by Sample Interval (98% Survival, 93% Recapture)",
    x = "Sample Interval",
    y = "Cumulative Proportion",
    color = "Decision Method",
    linetype = "Decision Method"
  ) +
  theme_JN() +
  theme(legend.position = "bottom") +
  facet_wrap(~outcome, scales = "free_y")

cumulative_plot_9398

```


We may then consider two things (1) Where the 'grey zone' exists when we reject null hypothesis and it may actually be true (e.g., the level of acceptance in 0.94 - 0.97). This is our type I error rate, which increase when trying to estimate close to thresholds.
(2) how we can control type I error if we use neutral method as it influences acceptance the least.

```{r}

ht_summary <- create_stopping_summary_ht(ht_simulation_results)

# Show how decision method affects outcomes across recapture rates
sensitivity_data <- ht_summary$trial_overview %>%
  select(true_survival_rate, recapture_rate, decision_method, prop_accept, prop_continue)

sens_plot <- ggplot(sensitivity_data, aes(x = recapture_rate, y = prop_accept, 
                            color = decision_method, linetype = decision_method)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = c("aggressive" = "blue", "neutral" = "black", "conservative" = "red")) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Acceptance Rate by Recapture Rate and Decision Method (98% survival)",
    x = "Recapture Rate",
    y = "Proportion Accepting H0",
    color = "Decision Method",
    linetype = "Decision Method"
  ) +
  theme_JN() +
  facet_wrap(~true_survival_rate)

sens_plot

```


```{r}

# For a specific example e.g., 98% true survival

sens_plot2 <- ggplot(sensitivity_data %>%
                       filter(true_survival_rate == 0.98), aes(x = recapture_rate, y = prop_accept, 
                            color = decision_method, linetype = decision_method)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  scale_color_manual(values = c("aggressive" = "blue", "neutral" = "black", "conservative" = "red")) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Acceptance Rate by Recapture Rate and Decision Method (98% survival)",
    x = "Recapture Rate",
    y = "Proportion Accepting H0",
    color = "Decision Method",
    linetype = "Decision Method"
  ) +
  theme_JN()

sens_plot2


# We can see that the effect is worst when recapture rate is lower - it reflects our real world confidence!

```



